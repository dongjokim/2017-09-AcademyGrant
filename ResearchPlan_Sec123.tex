%!TEX root = ResearchPlan_v2.tex

\section{Rationale}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:rationale}
The main emphasis of the ultra-relativistic heavy ion collisions (URHIC) is to study deconfined phase of the strongly interacting matter, the Quark-Gluon Plasma (QGP). Current widely accepted view is that the existence of the phase transition to QGP was experimentally established based on the analysis of  Au--Au collision data at center-of-mass energy $\sNN=200$~GeV measured at Relativistic Heavy Ion Collider (RHIC) located in Brookhaven Nation Laboratory, USA.

At the beginning of 2010, the Large Hadron Collider (LHC) at CERN became fully operational and the first Pb--Pb collisions at $\sNN=2.76$~TeV were recorded.  These measurements strenghtened the observations already made at RHIC, but the most importantly, they opened many new avenues to more detailed observations. 
The extreme center of mass energies accompanied by large luminosity delivered by the LHC machine allow heavy ion physics to enter an era of precision measurements. 
The proof of QGP existence, down to a level where there is hardly any doubt left, was the first step. 
Now we have started to map out more detailed features of this phase transition.
%, like the transport coefficients of the matter created in URHIC. 
This application will present an ambitious plan to pin down temperature dependence of the shear viscosity to entropy ratio $(\eta/s)$ and to search for a signatures of Mach cone shock waves, that have a long time anticipated to be found but have proven out to be difficult to observe. 
Observation of the Mach cone waves could uncover a direct experimental access to the speed of sound in QGP, one of the most fundamental property characterizing the deconfined state of matter. 
These objectives and measurement techniques will be discussed in Section~\ref{sec:objectives}.

The temperature dependence of the $\eta/s$ has some generic features that most of the known fluids obey. One such general behavior is that the ratio typically reaches its minimum value close to the phase transition region \cite{PhysRevLett.98.092301}. One can argue, using kinetic theory and uncertainty relations~\cite{PhysRevD.31.53}, that $\eta/s\sim0.1$ would be an order of magnitude for the lowest possible shear viscosity to entropy ratio in nature. Later it was found that one can calculate an exact lower bound $(\eta/s)_{\rm min}=1/4\pi\approx0.08$ using the AdS/CFT correspondence~\cite{PhysRevLett.94.111601} to certain class of conformal field theories. Hydrodynamical simulations supports as well the view that hot QGP matter indeed is close to that limit~\cite{Gale:2012rq}. This in turn may have an important implications to other fundamental physics goals. It is argued that such a low value might imply that thermodynamic trajectories for the expanding matter would lie close to the QCD critical end point, which is another subject of intensive experimental quest~\cite{PhysRevLett.98.092301}.
%which in turn would gain better prospects to search of critical end point~\cite{PhysRevLett.98.092301}.

Our group is fulfilling a strong involvement that Finland has in the ALICE experiment at CERN LHC. On top of that, two members of our group, the PI and senior researcher DongJo Kim, are members of the PHENIX experiment at RHIC, but those activities are not explicitly advanced with this application. Finnish participation to ALICE started with hardware oriented tasks. Helsinki Institute of Physics (HIP) was involved with bonding and assembly of the Silicon Strip Detector (SSD) and this project was successfully completed in 2006. Department of Physics at University of Jyv\"askyl\"a (JYFL) took the main responsibility in designing, building and maintaining the T0 fast timing detector that has provided not only a precise timing of the interaction but served also as a vertex, trigger and luminosity detector. The very successful T0 project is still on-going until the end of current LHC Run2 that finishes in December 2018. After that, ALICE will go trough a major upgrade where all central detectors are upgraded and also forward detectors T0, V0 and FMD will be merged into a new Fast Interaction Trigger detector  (FIT). The project leader of the T0 detector, Wladyslaw Trzaska, is also the project leader of the FIT. 
This detector system should be finished and commissioned during the Long Shutdown 2 (LS2) that takes place in 2019-2020. 
The Finnish participation to this effort is promoted by another Academy project application by Wladyslaw Trzaska in this same call.

Our group has designed and built the Trigger Region Units (TRU) system which derives the fast level-0 trigger from the electromagnetic calorimeter (EMCal) data. It provides the L0 single photon trigger to ALICE Central Trigger Processor (CTP) and it is combined into level-1 single photon and jet trigger. 
%In the case of single photon L1-trigger, STU does a logical OR action over all the TRU units. EMCal has also a jet trigger with higher patch size and trigger threshold. 
These triggers are very essential to all rare trigger data taking in the ALICE experiment. This project was so successful that the main TRU trigger design was adapted into another calorimeter, PHOton Spectrometer (PHOS), and also to Di-jet CALorimeter (DCAL) that is an extension of EMCal located in opposite side in azimuth. Both maintaining the L0 trigger and promoting analysis with EMCal+DCAL calorimeter systems are key ingredients of this application.
%, both extremely important Finnish contributions to the ALICE experiment. 
More precisely, the post doc we aim to hire to this project would take over the L0 trigger operations and work mainly in the jet analysis utilizing the calorimeter data.

Our group and particularly the HIP detector laboratory are also involved with the upgrade of the ALICE Time Projection Chamber (TPC). The TPC is the main tracking detector of the central barrel ($|\eta|<0.9$) and is optimized to provide charged particle momentum measurements down to 50~MeV/$c$ with excellent two-track separation, particle identification trough $dE/dx$ and vertex determination. The current design of the TPC allows the heavy ion data taking with maximum rate of 500 Hz. The rate is mainly limited by TPC gating grid that is needed to prevent the ion back flow to the drift volume. 
However, after LS2, the luminosity in heavy ion collisions will require the readout rate to be boosted up to 50 kHz. 
The goal of the TPC upgrade is to replace the multi-wire proportional readout chambers with the Gas Electron Multiplier (GEM) technology that allows the increase of the readout rate and to preserve PID capabilities and excellent momentum resolution.

Our group is responsible for the Quality Assurance of the whole 150 m2 of GEM foils. The QA work is done at the detector laboratory in HIP. Recently the same setup has been copied into Wigner Institute in Budapest. Our current PhD-student, Marton Vargyas, has helped in building the system in Hungary and also participated to measurements there as part of his Service Work duties for the ALICE experiment. 
The PhD-student that will be hired to this project will participate in the TPC upgrade as well.

\section{Objectives and expected results} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:objectives}

\subsection{Objectives of the research}

The large elliptic flow discovered at RHIC energies continuous to increase also in the highest beam energy $\sNN=5.02$~TeV currently reached in LHC. This has been predicted by calculations utilizing viscous hydrodynamics~\cite{PhysRevLett.99.172301} and microscopic transport models ~\cite{PhysRevLett.101.082302}.  These calculations also demonstrated that the shear viscosity to the entropy density ratio ($\eta/s$) of strongly interacting matter is close to a universal lower bound $1/4\pi$~\cite{PhysRevLett.94.111601} in heavy ion collisions at RHIC and LHC energies. One of the open questions is weather the viscosity of the matter is small enough that a high momentum parton, that would be supersonic in the QGP, could trigger a Mach Cone shock wave to the matter. Large viscosity might damp the shock wave before the freezeout of the fireball and hence it may not show up in the final (hadronic) observables~\cite{Bouras:2010nt,Bouras:2012mh,PhysRevC.90.024904}.

Early studies expected that the Mach cone shock wave would be observed as a double-hump structure in the away-side of azimuthal correlations~\cite{jabref}, relating to a opening angle of the cone. However, it turned out that the observed structure was explained fully by odd Fourier components of hydrodynamical flow that arises from initial geometry fluctuations 
in the collision of the relatively large nuclei~\cite{Luzum:2012wu,ALICE:2011ab}. This breakthrough started a rapid development in flow observables and analysis that has started a series of precision flow measurements. The simultaneous description of higher-order flow harmonics ($v_{n}$) and their \pt{}\ dependence turned out to provide important constraints to both the $\eta/s$ and to initial fluctuations~\cite{Luzum:2012wu}. Even further, correlations between magnitudes of two different flow harmonics, that already are very subtle flow measurements, can provide sensitivity to the temperature dependence of $\eta/s$ in the state-of-the-art hydrodynamic calculations~\cite{Niemi:2015qia} in combination with individual flow coefficients~\cite{ALICE:2016kpq}. The higher order ($v_5$ and higher) to lower order ($v_2$ or $v_3$) harmonic correlations can help to understand the viscous correction to the momentum distribution at freeze-out, which is one of the largest current uncertainties in the hydrodynamic models~\cite{PhysRevC.86.044908,Niemi:2015qia}. All in all, the advanced flow measurements are timely and very intensive line of research, and have significant potential to increase our understanding of QCD matter.

The full jet reconstruction in heavy ion environment has also gone trough rapid progress over the LHC time, see e.g. \cite{Abelev:2013kqa}. This has brought hydrodynamic response to the jet quenching again into the spot light because it affects various observables in detailed measurements with full jet reconstruction. The enhancement of low transverse momentum particles away from the quenched jets can be interpreted as a consequence of the energy-momentum transport by the Mach cone~\cite{Tachibana:2014lja}. 
The soft particles from the medium excitation affect also the fragmentation functions and the jet transverse profile~\cite{He:2015pra}.

Significant effort has been made to understand the measured fragmentation functions and the jet structure in heavy ion collisions~\cite{Chatrchyan:2011sx,Chatrchyan:2013kwa,Chatrchyan:2014ava,Adam:2015ewa,Khachatryan:2016erx}. Although the theory of parton energy loss has been successful in describing single particle spectra, namely the nuclear modification factor $R_{AA}$~\cite{Aamodt:2010jd}, the theoretical understanding of the in-medium parton shower is not yet fully achieved ~\cite{PhysRevLett.106.122002}. Therefore, in the absence of a consistent theory of jets in a medium, phenomenological studies of jet observables have relied to a large extend on modeling of medium modified parton showers~\cite{Armesto:2008qh,Renk:2010zx}. One can say that detailed modeling of medium modified jets, with a realistic hydrodynamical medium description such that the jet is coupled to the expanding medium, does not yet exists.

It has been realized that already the distribution of interaction vertices, where the hard parton was produced, can blur out the double-hump structure in two-particle correlations and hence make a straightforward observation of Mach cone more difficult~\cite{Tachibana:2015qxa}. Hence one needs to find out and exercise more detailed observables to pin down so called hard-soft interactions between the hard parton (that initiates the jet in the final state) traversing the medium of soft particles. The ambitious goal of this application is to make significant experimental progress towards this goal. Soft-hard interactions in general are dependent of the key features of the QGP, such as fluidity, sound velocity, viscosity and stopping power.

The practical implementation will be based on refining further the current flow measurements. Like discussed above, event-by-event correlations between magnitudes of different flow harmonics have turned out to be rich source of information and constraints to QGP properties. We aim to bias the event selection in such away that the event contains a single hard jet or a di-jet. This would be a new direction compared to presently studied event shape engineering, where one selects high-$v_2$  events for more detailed hadron correlation studies~\cite{ALICE:2016kpq}. Investigating modifications of various flow harmonic measurements in the presence of hard (di-)jet, as compared to just centrality selected collisions, requires a high statistics data sample and definitely makes use of the EMCal triggered data samples in \pbpb\ collisions.

This applications involves a post doc and PhD-student. Both would have hardware duties, but the main emphasis would be on the analysis goals. The flow correlations would be the PhD students thesis topic. Post doc would concentrate first on the jet studies and then later would lead the research in combining the jet and flow studies. Obvious risk is that at the end we cannot find strong signals that could be clearly related to hard-soft interactions. However, the plan is designed such that well defined and meaningful milestones can be set up. These will be refined in later parts of this application.

\subsection{Effects and impact beyond academia}

This application belongs into basic research that does not aim to immediate applications outside academia. However, CERN research has been very beneficial for example through its technology program, which directly benefited (Finnish) companies particularly during the LHC construction phase. CERN projects act as a driving force of technological advancement that may find their way for example to medical instrumentation. One observes in practice aging of electronics in high radiation environment.

The experimental techniques and various tools used for the data analysis are of common interest for rapidly developing industry since they require modern technologies. For example, a field-programmable gate array (FPGA) coding is our main part of the trigger logic development for EMCal trigger. Specific applications of FPGAs include digital signal processing, software-defined radio, ASIC prototyping, medical imaging, computer vision, speech recognition, cryptography, bioinformatics, computer hardware emulation, radio astronomy, metal detection and a growing range of other areas.

Technological aspects related to data acquisition (DAQ) systems for particle physics experiments following the natural path of the signals from the detector to the data processing are also broad interest of modern high-tech companies and any researches in general. The computer programming languages and software tools we are using in everyday for our researches are also needed skills for professionals in companies  who deal with the database, IT and many others. One concrete example would be mining of huge amounts of data in GRID environment. Two former members of our group have been hired to private sector based on their experience with the big data and programming skills.

\subsection{Publication plan}

ALICE Collaboration has made an effort to make the publication process such that all preliminary results that the collaboration produces would be effectively published. In general, CERN experiments publish in high impact journals and the internal review process helps to polish the results to very high quality. CERN has committed that all results will be published also in open access, which concretely promoted through SCOAP$^3$ project\footnote{SCOAP$^3$ stands for Supporting Consortium for Open Access Publishing in Particle Physics, see https://scoap3.org}. In practice, the scientific papers go to arXiv at the same time they are submitted into journal. Public analysis note and technical reports are published openly in the CERN's own CDS-database.

\section{Research methods and material, support from research environment} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%
\label{sec:researchmethods}

The field of heavy ion physics has very vivid cross talk between theoreticians and experimentalist world wide. This is seen, for example, in the development of the analysis methods~\cite{Poskanzer:1998yz,Bilandzic:2010jr}, detailed phenomenological modeling such that underlying theories are compared with the data~\cite{Burke:2013yra,Renk:2011gj,Niemi:2015qia} and tuning and development of the heavy ion event generators~\cite{Gyulassy:1994ew,Lin:2004en,Lokhtin2006}. For example, in the flow analysis, this interplay has been realized in the correlations between flow harmonics~\cite{Poskanzer:1998yz,ALICE:2011ab} and event plane angles~\cite{Aad:2014fla,Bhalerao:2014xra} that are crucial starting points in this application. Two particle correlations have been a long established tool in heavy ion physics~\cite{PhysRevLett.95.152301,PhysRevLett.97.052301} and this line is currently developing to various jet-hadron correlation, see e.g.~\cite{Khachatryan:2016tfj}. The research tools and methods are timely. They are under significant international interest and development, and belong to past experience of our group.

Observing the Mach cone in heavy ion collisions, or studying hard-soft interactions in general, has been a goal for a long time. After the observed cone-line structure in azimuthal correlations turned out be explained by the collective flow~\cite{ALICE:2011ab} and more detailed study of distribution of the hard interaction vertices was found out to smear the signal~\cite{Tachibana:2015qxa}, it is clear this proposal possesses a risk the positive observation may not come. However, the development in the field is astonishing, taking for example the correlations of the flow coefficients now measure correlations strengths that are order of part per million over the average values~\cite{ALICE:2016kpq} and the phenomena have a valid theoretical description. Heavy ion physics is clearly entering to the precision measurements where large statistics measurements enable extraction of weaker signals. Also, the steps towards the goal will provide results that are very valuable in discriminating and refining the current phenomenological models.

Obviously CERN is one of the best environments in the whole world to carry out this research. In ALICE experiment, the physics analyses are performed in the Physics Working Groups (PWG) that collect world wide researchers that are interest in a particular topic. Our group is involved in PWG's for correlation and flow analysis, and a PWG for jet analysis. The analysis work is supported and steered by the PWG's and a good interaction in the group provides a constant feedback and steady path to publish the results.

Department of Physics in Jyv\"askyl\"a has a long tradition in heavy ion physics dating back to early works by Vesa Ruuskanen and his collaborations \cite{VonGersdorff:1986tqh}. The experimental involvement started heavily when Jyv\"askyl\"a and HIP committed themselves to design and build the T0 timing detector to ALICE and production SSD modules to ALICE inner tracker~\cite{Dellacasa:1999kf}. Currently particle physics, and ultra-relativistic heavy ion collisions, is one of the main research lines in Jyv\"askyl\"a to which the department is fully committed itself. In wider perspective, it is also part of the "Structure of Matter with Accelerator Methods" to which Academy of Finland has granted profiling funding to University of Jyv\"askyl\"a. In theory side we have a strong group lead by Academy project leader and professor Kari Eskola and ERC Consolidator grant holder Tuomas Lappi, both internationally recognized experts in the heavy ion physics. Our group governs the Finnish participation to ALICE experiment trough a project in Nuclear Matter program in HIP. Together with the local cosmology and neutrino physics group, the department has build an extensive teaching program in various topics in particle physics up to a high level post graduate courses both in experimental and theoretical side. We have a common seminar with the theory group and untrammeled interaction between the groups.

Research results in this project come from analyzing the data with self-written codes. In following I will provide a brief description on how the data management goes in practice. 
The raw data for this project (order of 10 petabytes of raw data every calendar year) will be collected by the ALICE experiment at CERN. 
%The LHC project at CERN will collect huge amounts of data. For example, ALICE experiment will collect order of 10 petabytes of raw data every calendar year. 
Preservation and availability of this data is under the CERN's own data management plan and taken care of internationally.

All data measured by the ALICE experiment are available in LHC grid. Team of professionals will mine the raw detector data into more user friendly analysis files (Analysis Object Data (AOD)), where one has physical objects, like charged tracks or calorimeter clusters, from all good runs and events in some data taking periods. These files are stored, backed up and made available by CERN. Every research team in the collaboration can participate into Quality Assurance of the data and AOD's are updated by the findings of the analyzers.

In practice that data analysis has following guidelines: All the analysis code is written to so called AliRoot\footnote{http://aliroot-docs.web.cern.ch/aliroot-docs/} code packet, which is a GIT-repository (version control system) governed by CERN. Every analyzer belongs into some Physics Working Group (PWG) under which she develops her own analysis code. All the analysis code is first tested locally and then committed into this experiment wide GIT-repository, assuming that it passes quality criteria set by the experiment. By the latest at this point, the code that analyzer produced is stored and backed up with full version control. 

In ALICE, the data is recommended to be mined in so called ``lego train framework'' \cite{Zimmermann:2015owa}. This means that the analysis code that is committed into AliRoot will run over the desired data sets in the LHC grid environment semi-automatically and user can collect the ready analysis results from the data mining from grid to his local computer.

In the final state, analyzer develops an analysis and Figure plotting macro locally to reach the very final analysis results. These results are first approved by the PWG and later exposed to the whole collaboration to get the ALICE preliminary status. All analysis must be accompanied with very detailed internal analysis note. This note together with all analysis and figure plotting macros are stored in the internal pages of the ALICE experiment and hence all the documentation and all the final codes are fully stored, backed up with version control and made available to the collaboration. LHC experiments prepare also public analysis notes where certain analysis details, that will not come out along papers, are made publicly available. CERN has committed itself to fully open access publishing of all the scientific results obtained at CERN.

\nopagebreak
